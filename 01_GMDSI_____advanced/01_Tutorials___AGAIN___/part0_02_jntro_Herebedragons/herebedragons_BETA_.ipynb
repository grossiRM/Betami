{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     to be continued .... CTRL F          obs.loc[obsnme,\"weight\"] = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "import os\n",
    "import shutil\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import shutil\n",
    "import sys\n",
    "# sys.path.insert(0,os.path.join(\"..\",\"..\",\"dependencies\"))                               \n",
    "import pyemu\n",
    "import flopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_forecasts(pst, model_times=False):\n",
    "    pred_csv = os.path.join('..', '..', 'models', 'daily_freyberg_mf6_truth',\"pred_data.csv\")\n",
    "    assert os.path.exists(pred_csv)\n",
    "    pred_data = pd.read_csv(pred_csv)\n",
    "    pred_data.set_index('site', inplace=True)\n",
    "    \n",
    "    if type(model_times) == bool:\n",
    "        model_times = [float(i) for i in pst.observation_data.time.unique()]\n",
    "        \n",
    "    ess_obs_data = {}\n",
    "    for site in pred_data.index.unique().values:\n",
    "        site_obs_data = pred_data.loc[site,:].copy()\n",
    "        if isinstance(site_obs_data, pd.Series):\n",
    "            site_obs_data.loc[\"site\"] = site_obs_data.index.values\n",
    "        if isinstance(site_obs_data, pd.DataFrame):\n",
    "            site_obs_data.loc[:,\"site\"] = site_obs_data.index.values\n",
    "            site_obs_data.index = site_obs_data.time\n",
    "            sm = site_obs_data.value.rolling(window=20,center=True,min_periods=1).mean()\n",
    "            sm_site_obs_data = sm.reindex(model_times,method=\"nearest\")\n",
    "        #ess_obs_data.append(pd.DataFrame9sm_site_obs_data)\n",
    "        ess_obs_data[site] = sm_site_obs_data\n",
    "    obs_data = pd.DataFrame(ess_obs_data)\n",
    "\n",
    "    obs = pst.observation_data\n",
    "    obs_names = [o for o in pst.obs_names if o not in pst.nnz_obs_names]\n",
    "\n",
    "    # get list of times for obs name sufixes\n",
    "    time_str = obs_data.index.map(lambda x: f\"time:{x}\").values\n",
    "    # empyt list to keep track of misssing observation names\n",
    "    missing=[]\n",
    "    for col in obs_data.columns:\n",
    "        if col.lower()=='part_time':\n",
    "            obs_sufix = col.lower()\n",
    "        else:\n",
    "        # get obs list sufix for each column of data\n",
    "            obs_sufix = col.lower()+\"_\"+time_str\n",
    "        if type(obs_sufix)==str:\n",
    "            obs_sufix=[obs_sufix]\n",
    "\n",
    "        for string, oval, time in zip(obs_sufix,obs_data.loc[:,col].values, obs_data.index.values):\n",
    "                if not any(string in obsnme for obsnme in obs_names):\n",
    "                    missing.append(string)\n",
    "                # if not, then update the pst.observation_data\n",
    "                else:\n",
    "                    # get a list of obsnames\n",
    "                    obsnme = [ks for ks in obs_names if string in ks] \n",
    "                    if type(obsnme) == str:\n",
    "                        obsnme=[obsnme]\n",
    "                    obsnme = obsnme[0]\n",
    "                    if obsnme=='part_time':\n",
    "                        oval = pred_data.loc['part_time', 'value']\n",
    "                    # assign the obsvals\n",
    "                    obs.loc[obsnme,\"obsval\"] = oval\n",
    "                        ## assign a generic weight\n",
    "                        #if time > 3652.5 and time <=4018.5:\n",
    "                        #    obs.loc[obsnme,\"weight\"] = 1.0      \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_deps(template_ws, dep_dir=None):\n",
    "    # dep_dir=os.path.join('..','..','dependencies')\n",
    "    # for org_d in [os.path.join(dep_dir,\"flopy\"),os.path.join(dep_dir,\"pyemu\")]:\n",
    "    #     #org_d = i.path\n",
    "    #     new_d = os.path.join(template_ws, os.path.basename(org_d))\n",
    "    #     if os.path.exists(new_d):\n",
    "    #         shutil.rmtree(new_d)\n",
    "    #     shutil.copytree(org_d, new_d)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"linux\" in platform.platform().lower():\n",
    "    bin_path = os.path.join(\"..\",\"..\", \"bin_new\", \"linux\")\n",
    "elif \"darwin\" in platform.platform().lower() or \"macos\" in platform.platform().lower():\n",
    "    bin_path = os.path.join(\"..\",\"..\", \"bin_new\", \"mac\")\n",
    "else:\n",
    "    bin_path = os.path.join(\"..\", \"..\", \"bin_new\", \"win\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_bins(dest_path):\n",
    "    files = os.listdir(bin_path)\n",
    "    for f in files:\n",
    "        if os.path.exists(os.path.join(dest_path,f)):\n",
    "            os.remove(os.path.join(dest_path,f))\n",
    "        shutil.copy2(os.path.join(bin_path,f),os.path.join(dest_path,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_notebook(notebook_filename, path):\n",
    "    notebook_filename = os.path.join(path,notebook_filename)\n",
    "    with open(notebook_filename, encoding=\"utf8\") as f:\n",
    "        nb = nbformat.read(f, nbformat.NO_CONVERT)\n",
    "\n",
    "    ep = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "    ep.preprocess(nb, {'metadata': {'path': os.path.join(path)}})\n",
    "    with open(notebook_filename, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)\n",
    "\n",
    "    print(f'notebook complete:{notebook_filename}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_cleancopy(org_d, new_d, delete_orgdir=False):\n",
    "    # remove existing folder\n",
    "    if os.path.exists(new_d):\n",
    "        shutil.rmtree(new_d)\n",
    "    # copy the original model folder across\n",
    "    shutil.copytree(org_d, new_d)\n",
    "    print(f'Files copied from:{org_d}\\nFiles copied to:{new_d}')\n",
    "\n",
    "    if delete_orgdir==True:\n",
    "        shutil.rmtree(org_d)\n",
    "        print(f'Hope you did that on purpose. {org_d} has been deleted.')\n",
    "    #prep_bins(new_d)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(path_to_zip_file,directory_to_extract_to):\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory_to_extract_to)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_truth(truth_d):\n",
    "    \"\"\"Gets a realisation from the pest_setup backup folder and prepares the 'truth' model folder.\"\"\"\n",
    "    # remove existing folder\n",
    "    if os.path.exists(truth_d):\n",
    "        shutil.rmtree(truth_d)\n",
    "    # make truth dir\n",
    "    os.mkdir(truth_d)\n",
    "\n",
    "    # pest setup template folder\n",
    "    t_d = os.path.join('..', 'models', 'freyberg_pstfrom_pest_setup')\n",
    "    pst = pyemu.Pst(os.path.join(t_d, 'freyberg_mf6.pst'))\n",
    "\n",
    "    # choose realisation; this one gives headwater forecast > 95%\n",
    "    real=187\n",
    "    pst.parrep(parfile=os.path.join(t_d, 'prior_pe.jcb'), real_name=real, binary_ens_file=True)\n",
    "    pst.write_input_files(pst_path=t_d)\n",
    "\n",
    "    # run forward run so that parameter input files are updated; \n",
    "    pyemu.os_utils.run('python forward_run.py', cwd=t_d)\n",
    "\n",
    "    # load, rewrite and run simulation\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=t_d, verbosity_level=0)\n",
    "\n",
    "    sim.set_sim_path(truth_d)\n",
    "    sim.set_all_data_external(check_data=True)\n",
    "    sim.write_simulation()\n",
    "\n",
    "    # run mf6 so that model output files are available\n",
    "    pyemu.os_utils.run('mf6', cwd=truth_d)\n",
    "\n",
    "    # copy modpath7 model files\n",
    "    files = [f for f in os.listdir(t_d) if f.startswith('freyberg_mp') or f.startswith('pm.pg1')]\n",
    "    for f in files:\n",
    "        shutil.copy2(os.path.join(t_d, f),os.path.join(truth_d,f))\n",
    "\n",
    "    # run mp7\n",
    "    pyemu.os_utils.run(\"mp7 freyberg_mp.mpsim\", cwd=truth_d)\n",
    "\n",
    "\n",
    "    ## rename model output files because of silly design decisions a while back\n",
    "    #for f in ['heads.csv', 'sfr.csv']:\n",
    "    #    os.rename(os.path.join(truth_d, f), os.path.join(truth_d, f.split('.')[0]+'.meas.csv'))\n",
    "   \n",
    "    ##rename output file\n",
    "    #f='freyberg_mp.mpend'\n",
    "    #os.rename(os.path.join(truth_d, f), os.path.join(truth_d, f+'.meas'))\n",
    "    def make_obsdata(obs_df, obs_data, obs_sites=[], noise_scale=None):\n",
    "        for site in obs_df.columns:\n",
    "            if noise_scale==None:\n",
    "                noise_scale=abs(0.2*obs_df[site].mean())\n",
    "            y_true = obs_df[site].values\n",
    "            times_true = obs_df.index.values\n",
    "            if site in obs_sites:\n",
    "                x = np.linspace(obs_df.index[0], obs_df.index[-1], 500)\n",
    "                y = np.random.normal(np.interp(x, times_true, y_true), scale=noise_scale)\n",
    "            else:\n",
    "                x = times_true\n",
    "                y = y_true\n",
    "            arr = np.array([x.shape[0]*[site],x,y])\n",
    "            obs_data = pd.concat([obs_data, pd.DataFrame(arr.T)], axis=0, ignore_index=True)\n",
    "        obs_data.iloc[:,1:] = obs_data.iloc[:,1:].astype('float')\n",
    "        \n",
    "        return obs_data\n",
    "\n",
    "        \n",
    "    meas_sfr = pd.read_csv(os.path.join(truth_d,\"sfr.csv\"),\n",
    "                        index_col=0)\n",
    "    meas_hds = pd.read_csv(os.path.join(truth_d,\"heads.csv\"),\n",
    "                        index_col=0)\n",
    "\n",
    "    obs_sites = ['GAGE-1','TRGW-0-26-6','TRGW-2-26-6','TRGW-0-3-8','TRGW-2-3-8']\n",
    "\n",
    "    obs_data = pd.DataFrame()\n",
    "    obs_data = make_obsdata(meas_sfr, obs_data, obs_sites, noise_scale=None)\n",
    "    obs_data = make_obsdata(meas_hds, obs_data, obs_sites, noise_scale=0.1)\n",
    "    obs_data.columns=['site', 'time', 'value']\n",
    "    obs_data.set_index('site', inplace=True)\n",
    "\n",
    "    # add particle time obs\n",
    "    mp_obs = pd.read_csv(os.path.join(truth_d, 'freyberg_mp.mpend'), skiprows=6, header=None, usecols=[3,5], delim_whitespace=True)\n",
    "    obs_data.loc['part_time', ['time', 'value']] = '', mp_obs.iloc[:,-1].values[0]\n",
    "    obs_data.to_csv(os.path.join(truth_d, 'obs_data.csv'))\n",
    "    \n",
    "    return (print('Truth is updated.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction files\n",
    "def make_ins_from_csv(csvfile, tmp_d):\n",
    "    with open(os.path.join(tmp_d, csvfile),'r') as f:\n",
    "        lines = f.readlines()\n",
    "    colnames = lines[0].strip().lower().split(',')[1:]\n",
    "    with open(os.path.join(tmp_d, csvfile+'.ins'),'w') as f:\n",
    "        f.write(\"pif ~\\n\")\n",
    "        f.write(\"l1\\n\")\n",
    "        for line in lines[1:]:\n",
    "            row_time = float(line.split(',')[0])\n",
    "            line='l1 '\n",
    "            for i in colnames:\n",
    "                line+= f'~,~ !{i}:{row_time}! ' \n",
    "            line+='\\n'\n",
    "            f.write(line)\n",
    "    try:\n",
    "        pyemu.utils.run(f'inschek {csvfile}.ins {csvfile}', cwd=tmp_d)\n",
    "        print(f'ins file for {csvfile} prepared.')\n",
    "    except: \n",
    "        print('something is wrong with the observation & instruction pair. See INSCHEK.')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pst4pestchek(pstfile, par):\n",
    "    \"\"\"Hack to bypass NUMCOM/DERCOM conflict with PESTCHEK for pyemu-written control files. Could be better.\"\"\"\n",
    "    with open(pstfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [i.replace('point         1\\n', 'point\\n') for i in lines ]    \n",
    "    lines = [i.replace('0.0000000000E+00      1          \\n', '0.0000000000E+00      \\n') if any(i.startswith(xs) for xs in par['parnme']) else i for i in lines ]\n",
    "    with open(pstfile, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_part_ins(tmp_d):\n",
    "    # write a really simple instruction file to read the MODPATH end point file\n",
    "    out_file = \"freyberg_mp.mpend\"\n",
    "    ins_file = out_file + \".ins\"\n",
    "    with open(os.path.join(tmp_d, ins_file),'w') as f:\n",
    "        f.write(\"pif ~\\n\")\n",
    "        f.write(\"l7 w w w w w w !part_time!\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pest(tmp_d):\n",
    "    \"\"\"Prepares the PEST setup for part 1 of the tutorials. Used by the freyberg_pest_setup notebook.\"\"\"\n",
    "    \n",
    "    pyemu.os_utils.run('mf6', cwd=tmp_d)\n",
    "    pyemu.os_utils.run(r'mp7 freyberg_mp.mpsim', cwd=tmp_d)\n",
    "\n",
    "    # load simulation\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d,load_only=['DIS'], verbosity_level=0)\n",
    "    # load flow model\n",
    "    gwf = sim.get_model()\n",
    "    # get dis info\n",
    "    nrow, ncol = gwf.dis.nrow.get_data(), gwf.dis.ncol.get_data()\n",
    "    nlay=gwf.dis.nlay.get_data()\n",
    "\n",
    "    # make hk pars tpl\n",
    "    for lay in range(nlay):\n",
    "        filename = f'freyberg6.npf_k_layer{lay+1}.txt.tpl'\n",
    "        with open(os.path.join(tmp_d,filename),'w+') as f:\n",
    "            f.write(\"ptf ~\\n\")\n",
    "            for i in range(nrow):\n",
    "                for j in range(ncol):\n",
    "                    f.write(f\" ~     hk{lay+1}   ~\")\n",
    "                f.write(\"\\n\")\n",
    "        filename = f'freyberg_mp.ne_layer{lay+1}.txt.tpl'\n",
    "        with open(os.path.join(tmp_d,filename),'w+') as f:\n",
    "            f.write(\"ptf ~\\n\")\n",
    "            for i in range(nrow):\n",
    "                for j in range(ncol):\n",
    "                    f.write(f\" ~     ne{lay+1}   ~\")\n",
    "                f.write(\"\\n\")\n",
    "    # rch multiplier pars tpl\n",
    "    spdfiles = [f'freyberg6.rch_recharge_{i}.txt' for i in range(14)]\n",
    "    with open(os.path.join(tmp_d,'freyberg6.rch'),'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [item.replace('1.0', \" ~     rch0   ~\") if any(spd in item for spd in spdfiles) else item.replace('1.0', \" ~     rch1   ~\") for item in lines]\n",
    "    with open(os.path.join(tmp_d,'freyberg6.rch.tpl'),'w') as f:\n",
    "        f.write(\"ptf ~\\n\")\n",
    "        for l in lines:\n",
    "            f.write(l)\n",
    "\n",
    "    # make ins files\n",
    "    make_ins_from_csv('heads.csv', tmp_d)\n",
    "    make_ins_from_csv('sfr.csv', tmp_d)\n",
    "    make_part_ins(tmp_d)\n",
    "\n",
    "    # build lists of tpl, in, ins, and out files\n",
    "    tpl_files = [os.path.join(tmp_d, f) for f in os.listdir(tmp_d) if f.endswith(\".tpl\")]\n",
    "    in_files = [f.replace(\".tpl\",\"\") for f in tpl_files]\n",
    "    ins_files = [os.path.join(tmp_d, f) for f in os.listdir(tmp_d) if f.endswith(\".ins\")]\n",
    "    out_files = [f.replace(\".ins\",\"\") for f in ins_files]\n",
    "\n",
    "    # build a control file\n",
    "    pst = pyemu.Pst.from_io_files(tpl_files,in_files,\n",
    "                                            ins_files,out_files, pst_path='.')\n",
    "    pst.try_parse_name_metadata()\n",
    "    #tidy up\n",
    "    par=pst.parameter_data\n",
    "    par.loc[par['parnme'].str.startswith('hk'), ['parlbnd','parval1','parubnd', 'pargp']] = 0.05, 5, 500, 'hk'\n",
    "    par.loc['rch0', ['parlbnd','parval1','parubnd', 'partrans','pargp']] = 0.5, 1, 2, 'fixed', 'rch0'\n",
    "    par.loc['rch1', ['parlbnd','parval1','parubnd', 'partrans','pargp']] = 0.5, 1, 2, 'fixed', 'rch1'\n",
    "    par.loc['ne1', ['parlbnd','parval1','parubnd', 'partrans','pargp']] = 0.005, 0.01, 0.02, 'fixed', 'porosity'\n",
    "    \n",
    "    obs=pst.observation_data\n",
    "    obs['weight'] = 0\n",
    "    #obs.loc[:,\"time\"] = obs.obsnme.apply(lambda x: float(x.split(':')[-1]))\n",
    "    obs.loc[:,\"obgnme\"] = obs.obsnme.apply(lambda x: x.split(':')[0])\n",
    "    obs.loc['part_time',\"obgnme\"] = 'particle'\n",
    "\n",
    "    if platform.platform().lower().startswith(\"win\"):\n",
    "        with open(os.path.join(tmp_d, 'runmodel.bat'), 'w+') as f:\n",
    "            f.write('mf6\\n')\n",
    "            f.write('mp7 freyberg_mp.mpsim')\n",
    "\n",
    "        pst.model_command = 'runmodel.bat'\n",
    "    else:\n",
    "        with open(os.path.join(tmp_d, 'runmodel.sh'), 'w+') as f:\n",
    "            f.write('./mf6\\n')\n",
    "            f.write('./mp7 freyberg_mp.mpsim')\n",
    "        pyemu.os_utils.run(\"chmod 777 runmodel.sh\",cwd=tmp_d)\n",
    "        pst.model_command = './runmodel.sh'\n",
    "    pst.control_data.noptmax=0\n",
    "    pst.pestpp_options['forecasts'] = ['headwater:4383.5','tailwater:4383.5','trgw-0-9-1:4383.5', 'part_time']\n",
    "\n",
    "    ###-- Set OBSERVATION DATA AND WEIGHTS --###\n",
    "    # geat meas values\n",
    "    shutil.copy2(os.path.join('..', '..', 'models', 'daily_freyberg_mf6_truth','obs_data.csv'),\n",
    "                            os.path.join(tmp_d, 'obs_data.csv'))\n",
    "    obs_data = pd.read_csv(os.path.join(tmp_d, 'obs_data.csv'))\n",
    "    obs_data.site = obs_data.site.str.lower()\n",
    "    obs_data.set_index('site', inplace=True)\n",
    "    \n",
    "    # restructure the obsevration data \n",
    "    obs_sites = obs_data.index.unique().tolist()\n",
    "    model_times = obs.loc[:,obs_sites[0]].astype(float)\n",
    "    ess_obs_data = {}\n",
    "    for site in obs_sites:\n",
    "        #print(site)\n",
    "        site_obs_data = obs_data.loc[site,:].copy()\n",
    "        if isinstance(site_obs_data, pd.Series):\n",
    "            site_obs_data.loc[\"site\"] = site_obs_data.index.values\n",
    "        if isinstance(site_obs_data, pd.DataFrame):\n",
    "            site_obs_data.loc[:,\"site\"] = site_obs_data.index.values\n",
    "            site_obs_data.index = site_obs_data.time\n",
    "            sm = site_obs_data.value.rolling(window=20,center=True,min_periods=1).mean()\n",
    "            sm_site_obs_data = sm.reindex(model_times,method=\"nearest\")\n",
    "        #ess_obs_data.append(pd.DataFrame9sm_site_obs_data)\n",
    "        ess_obs_data[site] = sm_site_obs_data\n",
    "    ess_obs_data = pd.DataFrame(ess_obs_data)\n",
    "        \n",
    "    ## set the obs values\n",
    "    obs_names = pst.observation_data.obsnme.tolist()\n",
    "    obs_data = ess_obs_data.copy()\n",
    "    # for checking\n",
    "    org_nnzobs = pst.nnz_obs\n",
    "    org_nobs = pst.nobs\n",
    "    # empyt list to keep track of misssing observation names\n",
    "    missing=[]\n",
    "    for col in obs_data.columns:\n",
    "        # get obs list sufix for each column of data\n",
    "        obs_sufix = obs_data.index.map(lambda x: col.lower()+f':{x}' ).values\n",
    "        for string, oval, time in zip(obs_sufix, obs_data.loc[:,col].values, obs_data.index.values):\n",
    "            # get a list of obsnames\n",
    "            obsnme = [ks for ks in obs_names if string in ks] \n",
    "            # assign the obsvals\n",
    "            obs.loc[obsnme,\"obsval\"] = oval\n",
    "            # assign a generic weight\n",
    "            if time > 3652.5 and time <=4018.5:\n",
    "                obs.loc[obsnme,\"weight\"] = 1.0\n",
    "    # checks\n",
    "    assert org_nobs-pst.nobs==0, 'oh oh, new observations.'\n",
    "    assert len(missing)==0, f'The following obs are missing:\\n{missing}'\n",
    "\n",
    "    # set weights\n",
    "    obs = pst.observation_data\n",
    "    #obs.loc[obs.obgnme.str.startswith('gage-1'), 'weight'] = 1/ abs(0.1 *obs.loc[obs.obgnme.str.startswith('gage-1')].obsval)\n",
    "    obs.loc[obs.obgnme.str.startswith('gage-1'), 'weight'] = 0\n",
    "    obs.loc[obs.obgnme.str.startswith('trgw-0-26-6 '), 'weight'] = 1/ 0.1\n",
    "    prep_forecasts(pst, model_times)\n",
    "\n",
    "    # write and run pst check\n",
    "    pstfile = os.path.join(tmp_d,'freyberg.pst')\n",
    "    pst.write(pstfile)\n",
    "    clean_pst4pestchek(pstfile, par)\n",
    "    #pyemu.utils.run(f'pestchek {os.path.basename(pstfile)}', cwd=tmp_d)\n",
    "    print(f'written pest control file: {pstfile}')\n",
    "\n",
    "    return pst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ppoints(tmp_d='freyberg_mf6'):\n",
    "    pst = pyemu.Pst(os.path.join(tmp_d,'freyberg.pst'))\n",
    "    par = pst.parameter_data\n",
    "    par.loc['rch0', 'partrans'] = 'log'\n",
    "    obs = pst.observation_data\n",
    "    obs.loc[(obs.obgnme==\"gage-1\") & (obs['gage-1'].astype(float)<=4018.5), \"weight\"] = 0.005\n",
    "\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d, verbosity_level=0) #modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir,load_only=[])\n",
    "    gwf= sim.get_model()\n",
    "    ibound=gwf.dis.idomain.get_data()\n",
    "\n",
    "    sr = pyemu.helpers.SpatialReference.from_namfile(\n",
    "        os.path.join(tmp_d, \"freyberg6.nam\"),\n",
    "        delr=gwf.dis.delr.array, delc=gwf.dis.delc.array)\n",
    "    \n",
    "    ###--add SFR params\n",
    "    with open(os.path.join(tmp_d,'freyberg6.sfr_perioddata_1.txt.tpl'),'w+') as f:\n",
    "        f.write(\"ptf ~\\n\")\n",
    "        f.write(\"  1  inflow   ~     strinf   ~\")\n",
    "    pst.add_parameters(os.path.join(tmp_d,'freyberg6.sfr_perioddata_1.txt.tpl'), pst_path='.' )\n",
    "    par = pst.parameter_data\n",
    "    par.loc['strinf', ['parval1', 'parlbnd', 'parubnd', 'pargp']] = 500, 50, 5000, 'strinf'\n",
    "    ###--add  WEL params\n",
    "    wel_spd_files = [f for f in os.listdir(tmp_d) if '.wel_stress_period_data_' in f\n",
    "                        and int(f.split('.')[-2].split('_')[-1]) < 13\n",
    "                        and f.endswith('txt')]\n",
    "    for filename in wel_spd_files[1:12]:\n",
    "        with open(os.path.join(tmp_d, filename+'.tpl'), 'w+')as f:\n",
    "            f.write(\"ptf ~\\n\")\n",
    "        df = pd.read_csv(os.path.join(tmp_d, filename),delim_whitespace=True, header=None)\n",
    "        df.iloc[:-1, 3] = [f\"~     wel{i}   ~\" for i in df.iloc[:-1].index.values]\n",
    "        df.to_csv(os.path.join(tmp_d, filename+'.tpl'), index=False, header=None, sep=\"\\t\", mode='a')\n",
    "        # add parameters from tpl\n",
    "        pst.add_parameters(os.path.join(tmp_d,filename+'.tpl'), pst_path='.' )\n",
    "    par = pst.parameter_data\n",
    "    par.loc[par.pargp=='pargp','pargp', ] = 'wel'\n",
    "    par.loc[par.pargp=='wel',['parval1', 'parlbnd', 'parubnd', 'scale']] = 300, 10, 900, -1\n",
    "    ###--construct ppoints\n",
    "    prefix_dict = {0:[\"hk\"]} \n",
    "    df_pp = pyemu.pp_utils.setup_pilotpoints_grid(sr=sr,  # model spatial reference\n",
    "                                                ibound=ibound, # to which cells to setup ppoints\n",
    "                                                prefix_dict=prefix_dict, #prefix to add to parameter names\n",
    "                                                pp_dir=tmp_d, \n",
    "                                                tpl_dir=tmp_d, \n",
    "                                                every_n_cell=5) # pilot point spacing\n",
    "    pp_file_hk = os.path.join(tmp_d,\"hkpp.dat\")\n",
    "    assert os.path.exists(pp_file_hk)\n",
    "    # rch ppoints\n",
    "    prefix_dict = {0:[\"rch\"]} \n",
    "    df_pp = pyemu.pp_utils.setup_pilotpoints_grid(sr=sr,  # model spatial reference\n",
    "                                                ibound=ibound, # to which cells to setup ppoints\n",
    "                                                prefix_dict=prefix_dict, #prefix to add to parameter names\n",
    "                                                pp_dir=tmp_d, \n",
    "                                                tpl_dir=tmp_d, \n",
    "                                                every_n_cell=5) # pilot point spacing\n",
    "    pp_file_rch = os.path.join(tmp_d,\"rchpp.dat\")\n",
    "    assert os.path.exists(pp_file_rch)\n",
    "\n",
    "    v = pyemu.geostats.ExpVario(contribution=1.0, a=2500, anisotropy=1, bearing=0)\n",
    "    gs = pyemu.geostats.GeoStruct(variograms=v,nugget=0.0)\n",
    "    ok = pyemu.geostats.OrdinaryKrige(gs,df_pp)\n",
    "    df = ok.calc_factors_grid(sr,var_filename=\"freyberg.k.ref\", minpts_interp=1,maxpts_interp=10, )\n",
    "    ok.to_grid_factors_file(pp_file_hk+\".fac\")\n",
    "\n",
    "\n",
    "    hk_parval, hkub, hklb = pst.parameter_data.loc['hk1', ['parval1','parlbnd','parubnd']]\n",
    "    pst.drop_parameters(tpl_file=os.path.join(tmp_d,'freyberg6.npf_k_layer1.txt.tpl'), pst_path='.', )\n",
    "    # remove the .tpl file for tidyness\n",
    "    #os.remove(os.path.join(tmp_d,'freyberg6.npf_k_layer1.txt.tpl') )\n",
    "    par_pp = pst.add_parameters(os.path.join(tmp_d,'hkpp.dat.tpl'), pst_path='.' )\n",
    "    pst.parameter_data.loc[par_pp.parnme, ['parval1','parlbnd','parubnd', 'pargp']] = hk_parval, hkub, hklb, 'hk1'\n",
    "\n",
    "    df = ok.calc_factors_grid(sr,var_filename=\"freyberg.rch.ref\", minpts_interp=1,maxpts_interp=10, )\n",
    "    ok.to_grid_factors_file(pp_file_rch+\".fac\")\n",
    "    rch_parval, rchub, rchlb = pst.parameter_data.loc['rch0', ['parval1','parlbnd','parubnd']]\n",
    "    pst.parameter_data.loc['rch0', 'partrans'] = 'fixed'\n",
    "    pst.parameter_data.loc['rch1', 'partrans'] = 'fixed'\n",
    "    #pst.drop_parameters(tpl_file=os.path.join(tmp_d,'freyberg6.rch.tpl'), pst_path='.', )\n",
    "    par_pp = pst.add_parameters(os.path.join(tmp_d,'rchpp.dat.tpl'), pst_path='.' )\n",
    "    pst.parameter_data.loc[par_pp.parnme, ['parval1','parlbnd','parubnd', 'pargp']] = rch_parval, rchub, rchlb, 'rchpp'\n",
    "    rchspd_files = [i for i in os.listdir(tmp_d) if '.rch_recharge' in i]\n",
    "    if not os.path.exists(os.path.join(tmp_d, 'org_f')):\n",
    "        os.mkdir(os.path.join(tmp_d, 'org_f'))\n",
    "    for f in rchspd_files:\n",
    "        shutil.copy(os.path.join(tmp_d, f), os.path.join(tmp_d, 'org_f', f))\n",
    "    \n",
    "    with open(os.path.join(tmp_d, \"forward_run.py\"),'w') as f:\n",
    "        #add imports\n",
    "        f.write(\"import os\\nimport shutil\\nimport pandas as pd\\nimport numpy as np\\nimport pyemu\\nimport flopy\\n\")\n",
    "        # preprocess pilot points to grid\n",
    "        f.write(\"pp_file = 'hkpp.dat'\\n\")\n",
    "        f.write(\"hk_arr = pyemu.geostats.fac2real(pp_file, factors_file=pp_file+'.fac',out_file='freyberg6.npf_k_layer1.txt')\\n\")\n",
    "        # ...rch ppoints\n",
    "        f.write(\"pp_file = 'rchpp.dat'\\n\")\n",
    "        f.write(\"hk_arr = pyemu.geostats.fac2real(pp_file, factors_file=pp_file+'.fac',out_file='rch0_fac.txt')\\n\")\n",
    "        # multiply rch0 by recharge rates per spd\n",
    "        f.write(\"rch0 = np.loadtxt('rch0_fac.txt')\\n\")\n",
    "        f.write(\"files = [i for i in os.listdir('.') if '.rch_recharge' in i and int(i.split('.')[-2].split('_')[-1])<13]\\n\")\n",
    "        f.write(\"for f in files:\\n\")\n",
    "        f.write(\"    a = np.loadtxt(os.path.join('org_f',f))\\n\")\n",
    "        f.write(\"    a = a*rch0\\n\")\n",
    "        f.write(\"    np.savetxt(f, a, fmt='%1.6e')\\n\")\n",
    "        # run MF6 and MP7\n",
    "        f.write(\"pyemu.os_utils.run('mf6')\\n\")\n",
    "        f.write(\"pyemu.os_utils.run('mp7 freyberg_mp.mpsim')\\n\")\n",
    "    pst.model_command = ['python forward_run.py']\n",
    "\n",
    "    pst.control_data.pestmode = \"estimation\"\n",
    "    pst.pestpp_options[\"n_iter_base\"] = 1\n",
    "    pst.pestpp_options[\"n_iter_super\"] = 3\n",
    "\n",
    "    pst.write(os.path.join(tmp_d, 'freyberg_pp.pst'))\n",
    "    return print(\"new control file: 'freyberg_pp.pst'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_sv_vec_plot(inpst, U):\n",
    "    from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "    import ipywidgets as widgets\n",
    "    def SV_bars(SV=1,):\n",
    "        plt.figure(figsize=(13,4))\n",
    "        plt.bar(list(range(U.shape[0])),U[:,SV-1])\n",
    "        #plt.yscale('log')\n",
    "        plt.xlim([0,inpst.npar_adj+1])\n",
    "        plt.xticks(list(range(inpst.npar_adj+1)))\n",
    "        plt.title('Singular vector showing parameter contributions to singular vector #{0}'.format(SV))\n",
    "        plt.gca().set_xticks(range(U.shape[0]))\n",
    "        plt.gca().set_xticklabels(\n",
    "            inpst.parameter_data.loc[inpst.parameter_data.partrans != 'fixed']['parnme'].values, rotation=90);\n",
    "        return\n",
    "    return interact(SV_bars, SV=widgets.widgets.IntSlider(\n",
    "        value=1, min=1, max=20, step=1, description='Number SVs:',\n",
    "        disabled=False, continuous_update=True, orientation='horizontal', readout=True, readout_format='d'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freyberg(tmp_d):\n",
    "    # load simulation\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d, verbosity_level=0)\n",
    "    # load flow model\n",
    "    gwf = sim.get_model()\n",
    "\n",
    "    cols = pd.read_csv(os.path.join(tmp_d, 'heads.csv')).columns[1:].tolist()\n",
    "    obsxy = pd.DataFrame([i.replace('TRGW-','').split('-') for i in cols], columns=['layer','row','col'])\n",
    "    obsxy['x'] = [gwf.modelgrid.xycenters[0][int(i)+1] for i in obsxy['col'].values]\n",
    "    obsxy['y'] = [gwf.modelgrid.xycenters[1][int(i)+1] for i in obsxy['row'].values]\n",
    "\n",
    "    hdobj = gwf.output.head()\n",
    "    times = hdobj.get_times()\n",
    "    hds = hdobj.get_data(totim=times[-1])\n",
    "    hds[hds==1e30]=np.nan\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1, aspect='equal')\n",
    "    mm = flopy.plot.PlotMapView(model=gwf, ax=ax, layer=0)\n",
    "\n",
    "    mm.plot_grid(alpha=0.5)\n",
    "    mm.plot_inactive()\n",
    "    # Plot grid \n",
    "    # you can plot BC cells using the plot_bc() \n",
    "    mm.plot_bc('ghb')\n",
    "    mm.plot_bc('sfr')\n",
    "    mm.plot_bc('wel')\n",
    "\n",
    "    levels=np.linspace(np.nanmin(hds), np.nanmax(hds), 10)\n",
    "    ca = mm.contour_array(hds, masked_values=[1e30], levels=levels, colors='blue', linestyles ='dashed', linewidths=1)\n",
    "    plt.clabel(ca, fmt='%.1f', colors='k', fontsize=8)\n",
    "\n",
    "    ax.scatter(obsxy['x'],obsxy['y'], marker='x', c='k',)\n",
    "    plt.draw()\n",
    "    ax.set_yticklabels(labels=ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "    # plo crossection\n",
    "    ax = fig.add_subplot(1, 2, 2, aspect=200)\n",
    "    mm = flopy.plot.PlotCrossSection(model=gwf, ax=ax, line={'row':26})\n",
    "    arr = mm.plot_array(hds, masked_values=[1e30], cmap='Blues')\n",
    "    cb = plt.colorbar(arr, shrink=0.25, )\n",
    "    mm.plot_grid()\n",
    "    mm.plot_inactive()\n",
    "    mm.plot_bc('ghb')\n",
    "    mm.plot_bc('sfr')\n",
    "    mm.plot_bc('wel')\n",
    "    ax.set_ylim(0,45)\n",
    "    ax.set_ylabel('elevation (m)')\n",
    "    ax.set_xlabel('x-axis (m)')\n",
    "    ax.set_title('cross-section; row:26');\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "def prep_notebooks(rebuild_truth=True):\n",
    "    \"\"\"Runs notebooks, prepares model folders, etc.\"\"\"\n",
    "    # removes all the .ipynb checkpoint folders\n",
    "    for cdir, cpath, cf in os.walk('.'):\n",
    "        if os.path.basename(cdir).startswith('.ipynb'):\n",
    "            if os.path.isdir(cdir):\n",
    "                print('removing {}'.format(cdir))\n",
    "                shutil.rmtree(cdir)\n",
    "\n",
    "    # make sure there is a truth model; if not make one\n",
    "    truth_d = os.path.join('..','models','freyberg_mf6_truth')\n",
    "    if not os.path.exists(truth_d):\n",
    "        dir_cleancopy(org_d=os.path.join('..','models','freyberg_mf6'), \n",
    "                    new_d=truth_d)\n",
    "        pyemu.os_utils.run('mf6', cwd=truth_d)\n",
    "        # rename model output csv because of silly design decisions\n",
    "        for f in [f for f in os.listdir(truth_d) if f.endswith('.csv')]:\n",
    "            os.rename(os.path.join(truth_d, f), os.path.join(truth_d, f.split('.')[0]+'.meas.csv'))\n",
    "\n",
    "        f='freyberg_mp.mpend'\n",
    "        os.rename(os.path.join(truth_d, f), os.path.join(truth_d, f+'.meas'))\n",
    "\n",
    "    redo_part1=False\n",
    "    if redo_part1==True:\n",
    "        # run the intro_to_regression\n",
    "        run_notebook('intro_to_regression.ipynb', 'intro_to_regression')\n",
    "\n",
    "        # run the intro_to_pyemu\n",
    "        run_notebook('intro_to_pyemu.ipynb', 'intro_to_pyemu')\n",
    "\n",
    "        # run the sequence of Freyberg model notebooks\n",
    "        # run the freyberg model\n",
    "        run_notebook('freyberg_intro_model.ipynb', 'part1_intro_to_model')\n",
    "\n",
    "        # trial and error\n",
    "        run_notebook('freyberg_trial_and_error.ipynb', 'part1_trial_and_error')\n",
    "\n",
    "        # k only calib; takes a few minutes\n",
    "        run_notebook('freyberg_k.ipynb', 'part1_k')\n",
    "        dir_cleancopy(org_d=os.path.join('part1_k', 'freyberg_k'), \n",
    "                    new_d=os.path.join('..','models','freyberg_k'), \n",
    "                    delete_orgdir=True) # reduce occupied disk space\n",
    "\n",
    "    ## Part 2\n",
    "    # run the base pest setup and make a backup\n",
    "    run_notebook('freyberg_pstfrom_pest_setup.ipynb', 'part2_1_pstfrom_pest_setup')\n",
    "    dir_cleancopy(org_d=os.path.join('part2_1_pstfrom_pest_setup', 'freyberg6_template'), \n",
    "                new_d=os.path.join('..','models','freyberg_pstfrom_pest_setup'),\n",
    "                delete_orgdir=True) # reduce occupied disk space\n",
    "\n",
    "    if rebuild_truth==True:\n",
    "        print('Rebuilding truth.')\n",
    "        ### Generate the truth model; chicken and egg situation going on here.\n",
    "        # Need to re-run the pest setup notebook again to ensure that the correct Obs are used.\n",
    "        # Alternative is to accept some manual input here and just make sure the \"truth\" is setup correctly beforehand?\n",
    "        #...or just update the obs data...meh...this way burns a bit more silicon, but keeps things organized\n",
    "        make_truth(truth_d)\n",
    "\n",
    "        ### Run PEST setup again with correct obs values for consistency...\n",
    "        # run the base pest setup and make a backup\n",
    "        run_notebook('freyberg_pstfrom_pest_setup.ipynb', 'part2_1_pstfrom_pest_setup')\n",
    "        dir_cleancopy(org_d=os.path.join('part2_1_pstfrom_pest_setup', 'freyberg6_template'), \n",
    "                    new_d=os.path.join('..','models','freyberg_pstfrom_pest_setup'),\n",
    "                    delete_orgdir=True) # reduce occupied disk space\n",
    "        \n",
    "        # zip the prior cov; it is >100mb. prior_cov.jcb is in gitignore\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(os.path.join('..','models','prior_cov.zip'), 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "            zipf.write(os.path.join('..','models','freyberg_pstfrom_pest_setup','prior_cov.jcb'), \n",
    "            arcname='prior_cov.jcb')\n",
    "            zipf.close()\n",
    "    \n",
    "\n",
    "    # run the obs&weights notebook and make a backup\n",
    "    run_notebook('freyberg_obs_and_weights.ipynb', 'part2_2_obs_and_weights')\n",
    "    dir_cleancopy(org_d=os.path.join('part2_2_obs_and_weights', 'freyberg6_template'), \n",
    "                new_d=os.path.join('..','models','freyberg_obs_and_weights'),\n",
    "                delete_orgdir=True) # reduce occupied disk space\n",
    "\n",
    "\n",
    "\n",
    "    return print('Notebook folders ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_truth_k(m_d):\n",
    "\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=m_d, verbosity_level=0)\n",
    "    gwf= sim.get_model()\n",
    "   \n",
    "    k_truth= np.loadtxt(os.path.join('..','..', 'models', 'daily_freyberg_mf6_truth','truth_hk.txt'))\n",
    "    # downsample for model \n",
    "    k_truth_res = k_truth[::3,::3]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "    mm = flopy.plot.PlotMapView(model=gwf, ax=ax, layer=0)\n",
    "\n",
    "    ca = mm.plot_array(np.log10(k_truth_res), masked_values=[1e30],)\n",
    "    cb = plt.colorbar(ca, shrink=0.5)\n",
    "    cb.ax.set_title('$Log_{10}K$')\n",
    "\n",
    "    mm.plot_grid(alpha=0.5)\n",
    "    mm.plot_inactive()\n",
    "    #kmin = round(np.nanmin(k_truth_res))\n",
    "    #kmax = round(np.nanmax(k_truth_res))\n",
    "    #ax.text(1.10,.9,f\"max K: {kmax} m/d\\nmin K: {kmin} m/d\",  transform=ax.transAxes)\n",
    "    ax.set_title('Truth $K$');\n",
    "    return gwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_enchilada(gwf, m_d):\n",
    "    from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "    import ipywidgets as widgets\n",
    "    import sys\n",
    "    v = pyemu.geostats.ExpVario(1.0,a=200,anisotropy=1.0,bearing=45)\n",
    "    struct = pyemu.geostats.GeoStruct(variograms=v)\n",
    "    arr_dict = {\"test\":gwf.dis.idomain.get_data()[0]}\n",
    "\n",
    "    sr = pyemu.helpers.SpatialReference.from_namfile(\n",
    "                        os.path.join(m_d, \"freyberg6.nam\"),\n",
    "                        delr=gwf.dis.delr.array, delc=gwf.dis.delc.array)\n",
    "    bd = pyemu.helpers.kl_setup(num_eig=800,sr=sr,struct=struct,prefixes=['hk'],basis_file=\"basis.jco\",)\n",
    "    basis = pyemu.Matrix.from_binary(\"basis.jco\").to_dataframe()\n",
    "\n",
    "\n",
    "    i = basis.index.map(lambda x: int(x[1:5]))\n",
    "    j = basis.index.map(lambda x: int(x[-4:]))\n",
    "    nrow,ncol = gwf.dis.nrow.data,gwf.dis.ncol.data\n",
    "    #arr = np.zeros((nrow,ncol))\n",
    "    #arr[i,j] = basis.iloc[:,:100].values.sum(axis=1)\n",
    "    #plt.imshow(arr)\n",
    "    #plt.show()\n",
    "\n",
    "    ib = gwf.dis.idomain.array[0,:,:]\n",
    "    k_truth= np.loadtxt(os.path.join('..','..', 'models', 'daily_freyberg_mf6_truth','truth_hk.txt'))\n",
    "    # downsample for model \n",
    "    k_truth_res = k_truth[::3,::3]\n",
    "    k_truth_res[np.isnan(k_truth_res)] =0 \n",
    "    #k_truth_res[ib==0] = np.nan\n",
    "\n",
    "    truth_vec = np.atleast_2d(k_truth_res[i,j].flatten()).transpose()\n",
    "    k_truth_mask = np.log10(k_truth_res)\n",
    "\n",
    "    k_truth_mask[ib==0] = np.nan\n",
    "    mn = np.nanmin(k_truth_mask)\n",
    "    mx = np.nanmax(k_truth_mask)\n",
    "\n",
    "    def plot_enchilada(eig):\n",
    "        basis_arr = np.array(basis.values)\n",
    "        flat_arr = truth_vec.copy()\n",
    "        #np.atleast_2d(k_truth_res.flatten()).transpose()\n",
    "        #fig,ax = plt.subplots(ncols=2, figsize=(10,7),aspect='equal')\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax = fig.add_subplot(1, 3, 1, aspect='equal',)\n",
    "\n",
    "        arr = np.ones((nrow,ncol))\n",
    "        arr[i,j] = basis.iloc[:,eig].values\n",
    "        arr[ib==0] = np.nan\n",
    "        ax.imshow(arr)\n",
    "        ax.set_title('Plot of individual CV')\n",
    "\n",
    "        ax = fig.add_subplot(1, 3, 2, aspect='equal', )\n",
    "        basis_eig = basis_arr[:,:eig+1].transpose()\n",
    "        factors = np.dot(basis_eig, flat_arr).transpose()\n",
    "        factors = np.dot(factors, basis_eig)#.reshape(arr.shape)\n",
    "        recon = np.zeros((nrow,ncol))\n",
    "        recon[i,j] = factors.flatten()\n",
    "        recon[ib==0] = np.nan\n",
    "        recon[recon<1e-10] = 1e-10\n",
    "        ax.imshow(np.log10(recon),vmin=mn,vmax=mx)\n",
    "        ax.set_title('Reconstructed field')\n",
    "\n",
    "        ax = fig.add_subplot(1, 3, 3, aspect='equal',)\n",
    "\n",
    "        cb = ax.imshow(k_truth_mask,vmin=mn,vmax=mx)\n",
    "        plt.colorbar(cb,ax=ax,label=\"HK\")\n",
    "        ax.set_title('Truth $K$')\n",
    "\n",
    "        plt.suptitle('Using {0} SVs'.format(eig+1))\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(\"temp.pdf\")\n",
    "\n",
    "\n",
    "    return interact(plot_enchilada, eig=widgets.IntSlider(description=\"eig comp:\",\n",
    "                                          continuous_update=True, value=40, max=799));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_ppoint_names(par, tmp_d):\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d, verbosity_level=0) #modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir,load_only=[])\n",
    "    gwf= sim.get_model()\n",
    "    mg = gwf.modelgrid\n",
    "    cx = mg.xcellcenters\n",
    "    cy = mg.ycellcenters\n",
    "\n",
    "    ij = par.loc[par.pargp=='hk1', [\"parnme\",\"i\",\"j\"]]\n",
    "    ij[[\"i\",\"j\"]] = ij[[\"i\",\"j\"]].astype(int)\n",
    "    ij['x'] = cx[ij.i,ij.j]\n",
    "    ij['y'] = cy[ij.i,ij.j]\n",
    "\n",
    "    pp_file=os.path.join(tmp_d,\"hkpp.dat\")\n",
    "    df_pp = pd.read_csv(pp_file, delim_whitespace=True, header=None, names=['name','x','y','zone','parval1'])\n",
    "    df_pp = pd.merge(df_pp, ij, on=[\"x\",'y'])\n",
    "    df_pp.set_index(\"parnme\", inplace=True)\n",
    "    sorted_pnames = df_pp.index.values\n",
    "    return sorted_pnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arr2grid(ident_vals, tmp_d, title='Identifiability'):\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d, verbosity_level=0) #modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir,load_only=[])\n",
    "    gwf= sim.get_model()\n",
    "\n",
    "    sr = pyemu.helpers.SpatialReference.from_namfile(\n",
    "            os.path.join(tmp_d, \"freyberg6.nam\"),\n",
    "            delr=gwf.dis.delr.array, delc=gwf.dis.delc.array)\n",
    "\n",
    "    pp_file=os.path.join(tmp_d,\"hkpp.dat\")\n",
    "    new_ppfile = os.path.join(tmp_d,\"identpp.dat\")\n",
    "    df_pp = pd.read_csv(pp_file, delim_whitespace=True, header=None, names=['name','x','y','zone','parval1'])\n",
    "\n",
    "    # generate random values\n",
    "    df_pp.loc[:,\"parval1\"] = ident_vals\n",
    "    # save a pilot points file\n",
    "    pyemu.pp_utils.write_pp_file(new_ppfile, df_pp)\n",
    "    # interpolate the pilot point values to the grid\n",
    "    ident_arr = pyemu.geostats.fac2real(new_ppfile, factors_file=pp_file+\".fac\",out_file=None, )\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "    mm = flopy.plot.PlotMapView(model=gwf, ax=ax, layer=0)\n",
    "    ca = mm.plot_array(ident_arr, masked_values=[1e30],)\n",
    "    cb = plt.colorbar(ca, shrink=0.5)\n",
    "    mm.plot_grid(alpha=0.5)\n",
    "    mm.plot_inactive()\n",
    "    ax.set_title(f'{title}\\n`hk1` pilot point parameters');\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_arr(pe, tmp_d, numreals):\n",
    "    sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d, verbosity_level=0) #modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir,load_only=[])\n",
    "    gwf= sim.get_model()\n",
    "\n",
    "    sr = pyemu.helpers.SpatialReference.from_namfile(\n",
    "            os.path.join(tmp_d, \"freyberg6.nam\"),\n",
    "            delr=gwf.dis.delr.array, delc=gwf.dis.delc.array)\n",
    "\n",
    "    pp_file=os.path.join(tmp_d,\"hkpp.dat\")\n",
    "    df_pp = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(tmp_d,\"hkpp.dat.tpl\"))\n",
    "    #same name order\n",
    "    df_pp.sort_values(by='parnme', inplace=True)\n",
    "    pe.sort_index(axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    # generate random values\n",
    "    for real in range(numreals):\n",
    "        df_pp.loc[:,\"parval1\"] = pe.iloc[real,:].values\n",
    "        # save a pilot points file\n",
    "\n",
    "        pyemu.pp_utils.write_pp_file(pp_file, df_pp)\n",
    "        # interpolate the pilot point values to the grid\n",
    "        ident_arr = pyemu.geostats.fac2real(pp_file, factors_file=pp_file+\".fac\",out_file=None, )\n",
    "\n",
    "\n",
    "        ax = fig.add_subplot(int(numreals/5)+1, 5, real+1, aspect='equal')\n",
    "        mm = flopy.plot.PlotMapView(model=gwf, ax=ax, layer=0)\n",
    "        ca = mm.plot_array(np.log10(ident_arr), masked_values=[1e30],)\n",
    "\n",
    "        plt.scatter(df_pp.x, df_pp.y, marker='x', c='k', alpha=0.5)\n",
    "        \n",
    "        mm.plot_grid(alpha=0.5)\n",
    "        mm.plot_inactive()\n",
    "        ax.set_title(real+1)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "\n",
    "    cb = plt.colorbar(ca, shrink=0.5)\n",
    "    fig.tight_layout()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_mc(tmp_d):\n",
    "    # Repeats the regul notebook\n",
    "    # load the pre-constructed pst\n",
    "    pst = pyemu.Pst(os.path.join(tmp_d,'freyberg_pp.pst'))\n",
    "\n",
    "    pyemu.helpers.zero_order_tikhonov(pst, parbounds=True)\n",
    "\n",
    "    v = pyemu.geostats.ExpVario(contribution=1.0, a=2500.0)\n",
    "    gs = pyemu.geostats.GeoStruct(variograms=v,nugget=0.0)\n",
    "    df_pp = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(tmp_d,\"hkpp.dat.tpl\"))\n",
    "    cov = gs.covariance_matrix(df_pp.x, df_pp.y, df_pp.parnme)\n",
    "    pyemu.helpers.first_order_pearson_tikhonov(pst, cov, reset=False)\n",
    "\n",
    "    pst.reg_data.phimlim = pst.nnz_obs * 2\n",
    "    # when phimlim changes so should phimaccept, and is usually 5-10% higher than phimlim\n",
    "    pst.reg_data.phimaccept = 1.1 * pst.reg_data.phimlim\n",
    "\n",
    "    pst.pestpp_options.pop('n_iter_base')\n",
    "    pst.pestpp_options.pop('n_iter_super')\n",
    "\n",
    "    #update parameter data\n",
    "    par = pst.parameter_data\n",
    "    #update paramter transform\n",
    "    par.loc[:, 'partrans'] = 'log'\n",
    "\n",
    "    pst.control_data.noptmax = 20\n",
    "    pst.write(os.path.join(tmp_d, 'freyberg_reg.pst'))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading simulation...\n",
      "  loading simulation name file...\n"
     ]
    },
    {
     "ename": "MFDataException",
     "evalue": "An error occurred in package \"None\". The error occurred while loading package file in the \"load\" method.\nAdditional Information:\n(1) File E:\\15_REPOS\\00_Betami\\01_GMDSI_____advanced\\01_Tutorials___AGAIN___\\part0_02_jntro_Herebedragons\\part0_intro_to_svd\\master_pp\\mfsim.nam of type nam could not be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\gmdsitut\\Lib\\site-packages\\flopy\\mf6\\mfpackage.py:2779\u001b[0m, in \u001b[0;36mMFPackage.load\u001b[1;34m(self, strict)\u001b[0m\n\u001b[0;32m   2778\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2779\u001b[0m     fd_input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatautil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   2781\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2782\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\15_REPOS\\\\00_Betami\\\\01_GMDSI_____advanced\\\\01_Tutorials___AGAIN___\\\\part0_02_jntro_Herebedragons\\\\part0_intro_to_svd\\\\master_pp\\\\mfsim.nam'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMFDataException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#make_truth(os.path.join('..','models','freyberg_mf6_truth'))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#prep_notebooks(rebuild_truth=True)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#prep_pest(os.path.join(\"pest_files\"))\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     gwf \u001b[38;5;241m=\u001b[39m \u001b[43mflopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmf6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMFSimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_ws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpart0_intro_to_svd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaster_pp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_model()\n\u001b[0;32m      6\u001b[0m     svd_enchilada(gwf,os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart0_intro_to_svd\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaster_pp\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gmdsitut\\Lib\\site-packages\\flopy\\mf6\\modflow\\mfsimulation.py:144\u001b[0m, in \u001b[0;36mMFSimulation.load\u001b[1;34m(cls, sim_name, version, exe_name, sim_ws, strict, verbosity_level, load_only, verify_data, write_headers, lazy_io, use_pandas)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     use_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmfsimbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMFSimulationBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43msim_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexe_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43msim_ws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbosity_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gmdsitut\\Lib\\site-packages\\flopy\\mf6\\mfsimbase.py:786\u001b[0m, in \u001b[0;36mMFSimulationBase.load\u001b[1;34m(cls_child, sim_name, version, exe_name, sim_ws, strict, verbosity_level, load_only, verify_data, write_headers, lazy_io, use_pandas)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbosity_level\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m VerbosityLevel\u001b[38;5;241m.\u001b[39mnormal\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  loading simulation name file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 786\u001b[0m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# load TDIS file\u001b[39;00m\n\u001b[0;32m    789\u001b[0m tdis_pkg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtdis\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfstructure\u001b[38;5;241m.\u001b[39mMFStructure()\u001b[38;5;241m.\u001b[39mget_version_string()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gmdsitut\\Lib\\site-packages\\flopy\\mf6\\mfpackage.py:2788\u001b[0m, in \u001b[0;36mMFPackage.load\u001b[1;34m(self, strict)\u001b[0m\n\u001b[0;32m   2784\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m could not be opened.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2785\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_file_path(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpackage_type\n\u001b[0;32m   2786\u001b[0m         )\n\u001b[0;32m   2787\u001b[0m         type_, value_, traceback_ \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m-> 2788\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MFDataException(\n\u001b[0;32m   2789\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m   2790\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpackage_name,\n\u001b[0;32m   2791\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath,\n\u001b[0;32m   2792\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading package file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2793\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2794\u001b[0m             inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m   2795\u001b[0m             type_,\n\u001b[0;32m   2796\u001b[0m             value_,\n\u001b[0;32m   2797\u001b[0m             traceback_,\n\u001b[0;32m   2798\u001b[0m             message,\n\u001b[0;32m   2799\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulation_data\u001b[38;5;241m.\u001b[39mdebug,\n\u001b[0;32m   2800\u001b[0m         )\n\u001b[0;32m   2802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_blocks(fd_input_file, strict)\n",
      "\u001b[1;31mMFDataException\u001b[0m: An error occurred in package \"None\". The error occurred while loading package file in the \"load\" method.\nAdditional Information:\n(1) File E:\\15_REPOS\\00_Betami\\01_GMDSI_____advanced\\01_Tutorials___AGAIN___\\part0_02_jntro_Herebedragons\\part0_intro_to_svd\\master_pp\\mfsim.nam of type nam could not be opened."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #make_truth(os.path.join('..','models','freyberg_mf6_truth'))\n",
    "    #prep_notebooks(rebuild_truth=True)\n",
    "    #prep_pest(os.path.join(\"pest_files\"))\n",
    "    gwf = flopy.mf6.MFSimulation.load(sim_ws=os.path.join(\"part0_intro_to_svd\",\"master_pp\")).get_model()\n",
    "    svd_enchilada(gwf,os.path.join(\"part0_intro_to_svd\",\"master_pp\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
